# Blender Synthetic Data Capture - User Guide

Blender Synthetic Data Capture is a Blender addon for generating training data for 3D Gaussian Splatting and NeRF workflows. It produces camera-synchronized images and optional exports such as COLMAP files, depth maps, normals, and masks.

## Table of Contents

1. Installation
2. Quick Start
3. Framework Presets
4. Camera Configuration
5. Capture Settings
6. Coverage Analysis
7. Checkpoints and Resume
8. Training Integration
9. Export Formats
10. Troubleshooting
11. Keyboard Shortcuts

---

## Installation

### Requirements

- Blender 4.0 or newer (4.x or 5.x)
- GPU recommended for viewport preview and faster rendering
- Optional: training backends installed if you want to run training from Blender

### Installing the Addon

1. In Blender: Edit -> Preferences -> Add-ons
2. Click Install... and select `gs_capture_addon-<version>.zip` (or your packaged addon zip)
3. Enable "Blender Synthetic Data Capture"
4. Optional: configure training backends in the add-on preferences

### Training Backend Preferences (Optional)

Open Edit -> Preferences -> Add-ons -> GS Capture.

- 3D Gaussian Splatting
  - Path to repo containing `train.py`
  - Conda environment name (default: `gaussian_splatting`)
- Nerfstudio
  - Conda environment name (default: `nerfstudio`)
- GS-Lightning
  - Path to repo containing `main.py`
  - Conda environment name (default: `gs_lightning`)
- gsplat
  - Path to `gsplat/examples` (must contain `simple_trainer.py`)
  - Conda environment name (default: `gsplat`)

---

## Quick Start

1. Select one or more mesh objects in the 3D Viewport
2. Open the GS Capture panel (N key -> GS Capture)
3. Optional: choose a Framework Preset and apply it
4. Set the Output Path
5. Optional: click Preview to visualize camera positions
6. Click Capture Selected

---

## Framework Presets

Presets set recommended camera counts, Blender render resolution/format, and export options. You can tweak any settings after applying a preset.

| Preset | Cameras | Resolution | Format | Exports |
|---|---|---|---|---|
| 3D Gaussian Splatting | 100-300 | 1920x1080 | PNG | COLMAP |
| Instant-NGP | 100-200 | 800x800 | PNG | transforms.json |
| Nerfstudio (splatfacto) | 150-300 | 1920x1080 | PNG | transforms.json |
| Postshot | 50-150 | 1920x1080 | JPEG 95 | COLMAP + transforms.json |
| Polycam | 100-200 | 1080x1080 | JPEG 90 | COLMAP |
| Luma AI | 100-200 | 1920x1080 | PNG | COLMAP |
| gsplat | 100-300 | 1920x1080 | PNG | COLMAP + transforms.json |

---

## Camera Configuration

### Distribution Patterns

- Fibonacci Sphere: uniform sphere distribution
- Top Hemisphere: cameras only above the object
- Bottom Hemisphere: cameras only below the object
- Single Ring: one horizontal ring
- Multi Ring: multiple horizontal rings (use Ring Count)

### Key Parameters

- Camera Count: total cameras to generate
- Min/Max Elevation: vertical angle limits in degrees
- Distance Mode: Auto or Manual
- Distance Multiplier: scales auto distance
- Camera Distance: manual distance
- Focal Length: in mm

---

## Capture Settings

### Render Speed Preset

- Custom: use Blender render settings
- Fast (Eevee): low samples for speed
- Balanced (Eevee): higher samples
- Quality (Cycles): Cycles with 128 samples

Resolution, samples, engine, and file format are still controlled in Blender's Render Properties. The speed preset can override engine and samples for convenience.

### Export Options

- Export COLMAP Format: creates `sparse/0/` files
- Also Export COLMAP Binary: additionally writes `cameras.bin`, `images.bin`, `points3D.bin`
- COLMAP Initial Points: controls generated `points3D` count (default 5000)
- COLMAP Point Sampling:
  - Random Volume (Legacy): previous random volume behavior
  - Surface With Fallback: samples mesh surfaces (uses mesh/material color when possible), falls back to volume
- Export transforms.json: NeRF-style camera export
- Export Depth Maps: `depth/depth_0000.png` (16-bit)
- Export Normal Maps: `normals/normal_0000.exr`
- Export Object Masks: `masks/` directory

### Masks

- Mask Source
  - Alpha Channel: uses the rendered alpha channel
  - Object Index: uses Blender's Object Index pass
- Mask Format
  - Standard: `mask_0000.png`
  - GS-Lightning: `image_0000.png.png`

Alpha-based masks require Transparent Background enabled and a format that supports alpha (PNG or EXR).

---

## Coverage Analysis

Coverage analysis uses the preview cameras generated by the Preview button.

1. Click Preview to generate cameras
2. In Scene Analysis, click Analyze Coverage or Show Heatmap
3. If you adjust camera settings, regenerate the preview and re-run analysis

Automatic coverage validation is skipped for very dense meshes (over 200k vertices) to keep the UI responsive. Use the coverage heatmap for those scenes.

---

## Checkpoints and Resume

- Enable Checkpoints to save progress every N images
- Auto Resume will automatically continue from the last checkpoint if settings match
- If settings change or output folders are missing, the capture starts fresh

---

## Training Integration

### Supported Backends

- 3D Gaussian Splatting (original)
  - Requires COLMAP export (`sparse/0/`)
- Nerfstudio (splatfacto)
  - Requires `transforms.json`
- GS-Lightning
  - Requires COLMAP export
  - For mask support: enable Export Object Masks and set Mask Format to GS-Lightning
- gsplat
  - Accepts `transforms.json` or COLMAP
  - Requires `gsplat/examples` path and a conda environment with gsplat installed

### Start Training

1. Open the Training panel in the sidebar
2. Select a backend
3. Set Training Data Path (usually the capture output folder)
4. Set Training Output Path
5. Set iterations and optional extra arguments
6. Click Start Training

---

## Export Formats

### COLMAP

```
output/
  images/
    image_0000.png
    image_0001.png
  sparse/
    0/
      cameras.txt
      images.txt
      points3D.txt
      cameras.bin        # Optional
      images.bin         # Optional
      points3D.bin       # Optional
```

### transforms.json

Example frame entry:

```json
{
  "file_path": "./images/image_0000.png",
  "transform_matrix": [[...], [...], [...], [...]],
  "depth_file_path": "./depth/depth_0000.png",
  "mask_file_path": "./masks/mask_0000.png"
}
```

Depth and mask entries are only included when those exports are enabled.

### Optional Exports

- Depth: `depth/depth_0000.png` (16-bit normalized)
- Normals: `normals/normal_0000.exr` (world-space)
- Masks: `masks/mask_0000.png` or `masks/image_0000.png.png` (GS-Lightning)

---

## Troubleshooting

- No objects to capture
  - Select at least one mesh object

- Missing `sparse/0/`
  - Enable Export COLMAP Format and re-capture

- Training backend not installed
  - Check the add-on preferences for correct paths and conda environments

- Mask export from alpha fails
  - Enable Transparent Background and use PNG or EXR
  - For object-index masks, assign pass indices and use Object Index source

- Path too long on Windows
  - Use a shorter output path (e.g., `C:\gs_capture`) and avoid deep folder trees

---

## Keyboard Shortcuts

| Shortcut | Action |
|---|---|
| N | Toggle sidebar (GS Capture panel) |
| Esc | Cancel capture |
| Ctrl+Z | Undo last action |
